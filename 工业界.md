# CQA--工业界
## 目录
  * [1 任务](#1-任务)
  * [2 方法及模型](#2-方法及模型)
    * [2.1 用于FAQ的方法](#21-用于FAQ的方法)
    * [2.2 用于问答匹配的方法](#22-用于问答匹配的方法)
    * [2.3 用于Chatbot的方法](#23-用于Chatbot的方法)
    * [2.4 用于机器阅读理解的方法](#24-用于机器阅读理解的方法)
    * [2.5 用于跨领域迁移学习方法](#25-用于跨领域迁移学习方法)
    * [2.6 产品举例](#26-产品举例)
  
## 1 任务
### 1.1 任务定义
### 1.2 数据集
#### 格式
- 半结构化FAQ数据：问题-答案对。
- 非结构化知识文档：自由文本的形式，有些以段落、标题划分
- 用户query：通过对系统回答进行评估，将高质量的数据填加回知识库，形成“数据-模型”迭代循环。

#### 举例
| 标题 | 数据集提供者 | 说明 | 关键字 | 类别 | 更新日期| 论文 |
|---|---|---|---|---|---|---|
| [“技术需求”与“技术成果”项目之间关联度计算模型](https://www.datafountain.cn/competitions/359)                                                | CCF                            | 给定文本形式的技术需求和技术成果，以及需求与成果的关联度标签；其中技术需求与技术成果之间的关联度分为四个层级： 强相关、较强相关、弱相关、无相关                                                                                                                                                                   | 长文本；需求与成果匹配   | 长文本匹配         | 2020/2/28 |                                               |
| [CAIL2019相似案例匹配大赛](https://github.com/china-ai-law-challenge/CAIL2019/tree/master/scm)                                | 清华大学；中国裁判文书网                   | 对于每份数据，用三元组(A,B,C)来代表该组数据，其中A,B,C均对应某一篇文书。文书数据A与B的相似度总是大于A与B的相似度的，即sim(A,B)>sim(A,C)                                                                                                                                                 | 法律文书匹配        | 长文本匹配         | 2019/6    |                                               |
| [The BQ Corpus](https://github.com/CLUEbenchmark/CLUECorpus2020)                                                         | 哈工大(深圳)智能计算研究中心；微众银行         | 该数据集共有120000个句子对，来自银行一年中的咨询服务日志；句子对包含不同的意图，标记正负样本比例为1:1                                                                                                                                                                                    | 银行服务问句；意图匹配   | 短文本匹配；问句一致性检测 | 2018/9/4  | https://www.aclweb.org/anthology/D18-1536/ |
| [第三届拍拍贷“魔镜杯”大赛](https://ai.ppdai.com/mirror/goToMirrorDetail?mirrorId=1)                                                | 拍拍贷智慧金融研究院                     | train.csv文件包含3列，分别是标签（label，表示问题1和问题2是否表示相同的意思，1表示相同，0表示不同），问题1的编号（q1）和问题2的编号（q2）。本文件中出现的所有问题编号均在question.csv中出现过                                                                                                                        | 金融问题匹配        | 短文本匹配；问句匹配    | 2018/6/10 |                                               |
| [CCKS 2018 微众银行智能客服问句匹配大赛](https://biendata.com/competition/CCKS2018_3/data/)                                           | 哈工大(深圳)智能计算研究中心；微众银行         |                                                                                                                                                                                                                                            | 银行服务问句；意图匹配   | 短文本匹配；问句匹配    | 2018/4/5  |                                               |
| [AFQMC 蚂蚁金融语义相似度](https://dc.cloud.alipay.com/index?click_from=MAIL&_bdType=acafbbbiahdahhadhiih#/topic/intro?id=3) | 蚂蚁金服                           | 提供10万对的标注数据（分批次更新，已更新完毕），作为训练数据，包括同义对和不同义对                                                                                                                                                                                                 | 金融问句          | 短文本匹配；问句匹配    | 2018/4/25 |                                               |
| [cMedQA v1.0](https://www.mdpi.com/2076-3417/7/8/767)                                                                 | 寻药寻医网 和国防科技大学 信息系统及管理 学院       | 该数据集来源为寻医寻药网站中的提问和回答， 数据集做过匿名处理，提供的是包含 训练集中有50,000个问题，94,134个答案，平均每个问题、答案字符数分别为为120、212个； 验证集有2,000个问题，有3774个答案，问题和答案的平均字符数分别为117和212个； 测试集有2,000个问题，有3835个答案，问题和答案的平均字符数分别为119和211个； 数据集总量有54,000个问题，101,743个答案，平均每个问题和答案的字符数分别为119、212个； | 医疗问答匹配        | 问答匹配          | 2017/4/5  | https://www.mdpi.com/2076-3417/7/8/767     |
| [cMedQA2](https://www.mdpi.com/2076-3417/7/8/767)                                                                      | 寻药寻医网和国防科技大学信息系统及管理学院          | 该数据集来源为寻医寻药网站中的提问和回答， 数据集做过匿名处理，提供的是包含 训练集中有100,000个问题，188,490个答案，平均每个问题、答案字符数分别为为48、101个； 验证集有4,000个问题，有7527个答案，问题和答案的平均字符数分别为49和101个； 测试集有4,000个问题，有7552个答案，问题和答案的平均字符数分别为49和100个； 数据集总量有108,000个问题，203,569个答案，平均每个问题和答案的字符数分别为49、101个；  | 医疗问答匹配        | 问答匹配          | 2018/11/8 | https://www.mdpi.com/2076-3417/7/8/767     |
| [OPPO手机搜索排序query-title语义匹配数据集。](https://pan.baidu.com/s/1Hg2Hubsn3GEuu4gubbHCzw) (密码7p3n)                               | OPPO                           | 该数据集来自于OPPO手机搜索排序优化实时搜索场景, 该场景就是在用户不断输入过程中，实时返回查询结果。 该数据集在此基础上做了相应的简化， 提供了一个query-title语义匹配，即ctr预测的问题。                                                                                                                                    | 问题标题匹配， ctr预测 | 相似度匹配         | 2018/11/6 |                                               |
| [中国健康信息处理会议 举办的医疗问题相似度 衡量竞赛数据集](https://biendata.com/competition/chip2018/)                                              | CHIP 2018-第四届中国健康信息处理会议（CHIP） | 本次评测任务的主要目标是针对中文的真实患者健康咨询语料，进行问句意图匹配。 给定两个语句，要求判定两者意图是否相同或者相近。 所有语料来自互联网上患者真实的问题，并经过了筛选和人工的意图匹配标注。 数据集经过脱敏处理，问题由数字标示 训练集包含20000条左右标注好的数据（经过脱敏处理，包含标点符号）， 测试集包含10000条左右无label的数据（经过脱敏处理，包含标点> 符号）。                                          | 医疗问题相似度 匹配    | 相似度匹配         | 2018      |                                               |



### 1.3 评测标准
- 查全率：用以评价系统对于潜在答案寻找的全面程度。例如：在回答的前30%中保证一定出现正确答案。
- 查准率：即准确率，top n个答案包含正确答案的概率。这一项与学术界一致。
- 问题解决率：与具体业务和应用场景紧密相关
- 用户满意度/答案满意度：一般对答案满意度的评价方式是在每一次交互后都设置一个评价，客户可以对每一次回答进行评价，评价该答案是否满意。但是这样的评价方式容易让客户厌烦，因为客户是来解决问题的，不是来评价知识库里面的答案是否该优化。
- 问题识别率/应答准确率：指智能客服机器人正确识别出客户的问题数量在所有问题数中的占比。目前业内评价智能机器人比较常用的指标之一。
- 问题预判准确率：指用户进入咨询后，智能客服机器人会对客户可能咨询的问题进行预判。
> 该评测标准是基于京东大数据优势，背靠用户画像体系。通过京东长期数据积累和模型给每个用户添加各种标签，可以提供更个性化和人性化的服务。例如，京东JIMI了解用户的性别、情绪类型、近期购买历史等。当用户开始交流时，就会猜到他可能要询问一个关于母婴商品的使用方法或是一个售后单的退款情况，这就是问题预判。如果预判准确的话，只需在几次甚至一次的交互中获得智能客服机器人专业的问题解答，从而缩短客户咨询时长。
- 意图识别准确率：要想解答用户的问题，机器人首先需要结合上下文环境，从用户提问中准确识别用户咨询的意图是什么，然后返回对应的答案。
- 拦截率：机器人代替人工解决的用户咨询比例
- 24H未转人工率：指客户咨询了智能机器人后的24H内是否有咨询人工客服

## 2 方法及模型
### 2.1 用于FAQ的方法
Frequently Asked Questions的缩写，意思是“**常见问题解答**”。
#### 实现方法
1. **QA匹配：用户输入Query与候选的所有Answer的匹配**。通过计算用户输入Query与FAQ语料集中Answer之间的相关度，选出相关度最高的Answer，返回给用户。
2. **QQ匹配：用户输入Query与历史语料库里找最相似的Query，然后返回找到的Query对应的Answer**。计算用户输入Query和Question的相似度。通过计算用户输入Query与FAQ语料集中Question之间的相似度，选出相似度最高的Question，再通过Q-A map找到相应的答案返回给用户。
3. **QA和QA匹配结合：结合用户输入Query和Answer的之间的相关性以及用户输入Query和Question的相似度**。通过结合相关性和相似度，选出最匹配的Answer，返回给用户。
**工业界使用QQ匹配方式比较多**。如蚂蚁金服的智能机器人利用的是QQ匹配的方式。
#### 匹配方法
1. **规则匹配**
- 目前，很多机器人都有规则匹配的部分。
- 优点：可控、高效、易于实现
- 如句式法，针对FAQ库中的标问和相似问进行分词、提炼出大量的概念，并将上述概念组合，构成大量的句式，句式再进行组合形成标问。
2. **深度学习语义匹配**
- 语义匹配的技术，从早期的DSSM，利用词袋模型，计算句之间的相似度；到后面利用LSTM-DSSM来捕捉长时间序列的语义信息；再到现在的基于BERT的语义相似度计算与匹配。
- 本质上，其实都是提取句子的语义特征，再通过数学运算计算相似度。

### 2.2 用于问答匹配的方法
在拥有较大数据量积累的场景，一般采用有监督的深度神经网络，可以解析文本并抽取高层语义。

- **深度学习多分类模型（CNN\DNN\LSTM\…）**

问答匹配任务在大多数情况下可以转化为二分类或多分类任务。神经网络中会有两大输入，左边N会输入结构化数据，比如个人属性以及浏览操作历史纪录，右边V会输入一些非结构化数据，比如前几轮问的问题和序列，对于这些非结构化的数据我们会有句子编码器解析这些数据，当需要考虑到句子的语序关系的时候会使用CNN或者RNN网络结构；上层的话，会结合用户的Embedding和句子的Embedding去输出。但是工业真正的场景中，用户问题的问题个数是不固定的，所以会把最后一层Softmax更改为多个二分类模型。
- **基于Siamese networks神经网络架构**

这是一种相似性度量方法，内部采用深度语义匹配模型（DSMM，Deep Structured Semantic Model），该方法在检索场景下使用点击数据来训练语义层次的匹配

### 2.3 用于Chatbot的方法
Chatbot可以自然语言对话的方式来帮助用户解答问题，比传统死板的用户界面要更友好。通常Chatbot包括两个部分：IR 模块和生成模块。针对用户的问题，IR 模块从 QA 知识库中检索到对应的答案，生成模块再用一个 Seq2Seq 模型来对搜索结果做评估，从而达到优化的效果。整个方法分为四个模块，顶层结构如图：
![image](https://github.com/BDBC-KG-NLP/CQA-Survey/blob/master/images/VBcD02jFhgkDdMnpz4O4ByPrUWVcT3N6cOekP4HJyhRicF38UtiaIf8EtqgNcQRPVuNmZnXfpmCqDcMHCSKP98WA.jpeg)
1. QA知识库 
本文从在线的真人用户服务log里提取问答对作为QA知识库。过滤掉不包含相关关键词的QA，最后得到9164834个问答对。 
2. IR模块 
利用倒排索引的方法将每个单词隐射到包含这个单词的一组问句中，并且对这些单词的同义词也做了索引，然后利用BM25算法来计算搜索到的问句和输入问句的相似度，取最相似问句的答案。 
3. 生成模型 
生成模型是一个attentive seq2seq的结构，如图所示：
![image](https://github.com/BDBC-KG-NLP/CQA-Survey/blob/master/images/VBcD02jFhgkDdMnpz4O4ByPrUWVcT3N6UGKxwDMRMZkvYpGOufORwO3vAL6cf2kn1jQic8GwMrMkOLkSNiaGcOCg.jpeg)
4. rerank 模块
使用的模型和上面是一样的，根据输入问题来为候选答案打分，使用平均概率作为评分函数。

### 2.4 用于机器阅读理解的方法
Machine Reading步骤：
- 文章片段定位：针对用户问题，召回候选文档段落集合，借助文本分类、检索或者问题模板辅助；
- 输入预处理：格式归一，特征预计算问题，及相应段落向量表征，生成文档结构标签；
- 在线预测服务： GPU-Based模型加载及服务驱动，预测段落中词或符号得分；
- 后处理机制：基于动态规划选取最佳文本短语作为输出，拒识：判断是否拒绝回答。

模型结构：
- Embedding Layer：问题及篇章中词向量表示，RNN网络捕捉语序间依赖；
- Attention Layer：对齐问题和篇章，语义相似性计算，引进注意力机制，带着问题找答案；
- Modeling Layer Question-Aware：篇章建模，充分利用问题中信息；
- Output Layer：基于问题和篇章匹配预测答案位置。

### 2.5 用于跨领域迁移学习方法
迁移学习的模型有两类，一种是unsupervised，另外一种是supervised。前者假设完全没有目标领域的标注数据，后者假设仅有少部分目标领域的标注数据。在实际的商业应用中主要以supervised的迁移学习技术为主，同时结合深度神经网络（DNN）。在这个设定下主要有两种框架：
- Fully-Shared Model:用于比较相似的两个领域。
- Specific-Shared Model: 用于相差较大的两个领域。
![image](https://github.com/BDBC-KG-NLP/CQA-Survey/blob/master/images/Screen%20Shot%202020-04-20%20at%207.36.26%20PM.png)

### 2.6 产品举例
#### 产品1: YiBot
**简介**
- YiBot是由深圳追一科技有限公司自主研发，应用目前最前沿的自然语言处理及深度学习算法，为企业级客户提供的一套智能客服机器人系统。

**FAQ问题优化**
> YiBot的FAQ问题优化是从用户问题和智能客服机器人的回答出发，合理拆分、合并已有FAQ，并优化问句和答案；同时采用问句聚类技术，挖掘新知识点，补充更新已有知识点，淘汰废弃知识点，形成一个正向循环，不断优化知识结构，提高拦截率。
- **FAQ发现**
> 将用户问句进行聚类，对比已有的FAQ，发现并补足未覆盖的知识点。将FAQ与知识点一一对应。
- **FAQ的拆分与合并**
> FAQ拆分是当一个FAQ里包含多个意图或者说多种情况的时候，YiBot后台会自动分析触达率较高的FAQ，聚类FAQ对应的问句，按照意图将其拆分开来。
- **FAQ合并**
> 最终希望希望用户的每一个意图能对应到唯一的FAQ，这样用户每次提问的时候，系统就可以根据这个意图对应的FAQ直接给出答案。而如果两个FAQ意思过于相近，那么当用户问到相关问题时，就不会出现一个直接的回答，而是两个意图相关的推荐问题，这样用户就要再进行一步选择操作。这时候YiBot就会在后台同样是分析触达率较高的FAQ，分析哪一些问句总是被推荐相同的答案，将问句对应的意图合并。
- **淘汰机制**
> 分析历史日志，采用淘汰机制淘汰废弃知识点，如已下线业务知识点等。

**FAQ答案优化**
- **挖掘对话，进行答案优化**

> 如果机器人已经正确识别意图但最后仍然转人工，说明知识库的答案不对，需要进一步修正这一类知识点相对应的答案。
- **分析头部场景，回答应用文本、图片、自动化解决方案等多元化方式**
> 比如在电商场景中，经常会有查询发货到货时间、订单状态等的场景。利用图示指引、具体订单处理等方式让用户操作更便捷。

#### 产品2: [百度AnyQ--ANswer Your Questions](https://github.com/baidu/AnyQ)

**简介**

- AnyQ开源项目主要包含面向FAQ集合的问答系统框架、文本语义匹配工具SimNet。

**系统框架**

- AnyQ系统框架主要由Question Analysis、Retrieval、Matching、Re-Rank等部分组成。
- 框架中包含的功能均通过插件形式加入，如Analysis中的中文切词，Retrieval中的倒排索引、语义索引，Matching中的Jaccard特征、SimNet语义匹配特征，当前共开放了20+种插件。

**特色**

- **特色1 框架设计灵活，插件功能丰富，有助于开发者快速构建、快速定制适用于特定业务场景的 FAQ 系统**
> AnyQ 系统集成了检索和匹配的丰富插件，通过配置的方式生效；以相似度计算为例，包括字面匹配相似度 Cosine、Jaccard、BM25 等，同时包含了语义匹配相似度。且所有功能都是通过插件形式加入，用户自定义插件，只需实现对应的接口即可，如 Question 分析方法、检索方式、匹配相似度、排序方式等。
- **特色2 极速语义检索**
> 语义检索技术将用户问题和 FAQ 集合的相似问题通过深度神经网络映射到语义表示空间的临近位置，检索时，通过高速向量索引技术对相似问题进行检索。
- **特色3 业界领先语义匹配技术 SimNet**
> AnyQ 使用 SimNet 语义匹配模型构建文本语义相似度，克服了传统基于字面匹配方法的局限，增强 AnyQ 系统的语义检索和语义匹配能力。
- **其他**：针对无任何训练数据的开发者，AnyQ 还包含了基于百度海量数据训练的语义匹配模型，开发者可零成本直接使用。

#### 产品3: [腾讯知文--结构化FAQ问答引擎](https://cloud.tencent.com/developer/article/1172017  )
基于结构化的FAQ的问答引擎流程由两条技术路线来解决
- 无监督学习，基于快速检索
- 有监督的学习，基于深度匹配

**无监督的快速检索方法**

采用了三个层次的方法来实现快速检索的方法
- **层次1：基础的TFIDF提取query的关键词，用BM25来计算query和FAQ库中问题的相似度**。这是典型的词汇统计的方法，该方法可以对rare word比较鲁棒，但同时也存在词汇匹配缺失的问题。
- **层次2：采用了language model（简写LM）的方法**。主要使用的是Jelinek-Mercer平滑法和Dirichlet平滑法，对于上面的词汇匹配问题表现良好，但是也存在平滑敏感的问题。
- **层次3：最后一层使用Embedding，采用了LSA/word2vec和腾讯知文自己提出的Weighted Sum/WMD方法**，以此来表示语义层面的近似，但是也同样引发了歧义问题。

**监督的深度匹配方法**

采用了两条思路
- **思路1 基于Siamese networks神经网络架构**。这是一种相似性度量方法，内部采用深度语义匹配模型（DSMM，Deep Structured Semantic Model），该方法在检索场景下使用点击数据来训练语义层次的匹配
- **思路2 Interaction-based networks，同时对问题和答案进行特征加权的Attention方案**。

#### 产品4: [阿里小蜜](https://www.alixiaomi.com/#/)
**自然语言理解(NLU)方法**

- 无样本冷启动方法：写一套简单易懂的规则表示语法
- 小样本方法：我们先整理出一个大数量级的数据，每一个类目几十条数据，为它建立 meta-learning 任务。对于一个具体任务来说：构建支撑集和预测集，通过 few-shot learning 的方法训练出 model，同时与预测集的 query 进行比较，计算 loss 并更新参数，然后不断迭代让其收敛。这只是一个 meta-learning 任务，我们可以反复抽样获得一系列这样的任务，不断优化同一个模型。在线预测阶段，用户标注的少量样本就是支撑集，将 query 输入模型获得分类结果。模型的神经网络结构分为3部分，首先是 Encoder 将句子变成句子向量，然后再通过 Induction Network 变成类向量，最后通过 Relation Network 计算向量距离，输出最终的结果。具体地，Induction Network中把样本向量抽象到类向量的部分，采用 matrix transformation 的方法，转换后类边界更清晰，更利于下游 relation 的计算。在 Induction Network 的基础上，又可以引入了 memory 机制，形成Memory-based Induction Network ，目的是模仿人类的记忆和类比能力，在效果上又有进一步提升。
- 多样本方法：构建一个三层的模型，最底层是具有较强迁移能力的通用模型 BERT，在此基础上构建不同行业的模型，最后用相对较少的企业数据来训练模型。这样构建出来的企业的 NLU 分类模型，F1 基本都在90%+。性能方面，因为模型的结构比较复杂，在线预测的延时比较长，因此通过知识蒸馏的方法来进行模型压缩，在效果相当的同时预测效率更快了。

**技术难点**

1. 数据冷启动的问题
> 解决方案：大致有两种办法：
> - 一是先用一个通用的模型，等到数据足够多的时候优化这个模型；
> - 第二种是先用规则的方法做，先把这个模块做起来，等到数据足够多的时候，再来启用模型的方法，这两种方法都可以走的通，但是要根据具体的情况来具体分析。
2. 用户问题较为口语化，包含大量省略、指代等现象；
3. 用户问题复杂多样，基于字面信息很难精准匹配语义相同问题；
4. 实际产品应用中，对系统鲁棒性、整体性能要求较高

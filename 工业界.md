# CQA--工业界
## 任务
### 任务定义
### 数据集
#### 格式
- 半结构化FAQ数据：问题-答案对。
- 非结构化知识文档：自由文本的形式，有些以段落、标题划分
- 用户query：通过对系统回答进行评估，将高质量的数据填加回知识库，形成“数据-模型”迭代循环。

#### 举例
| 数据集 | 数据概览 |
| ----- | -------- |
| 保险知道 | 8000 多条保险行业问答数据，包括用户提问、网友回答、最佳回答  |
| 安徽电信知道 | 15.6 万条电信问答数据，包括用户提问、网友回答、最佳回答 |
| 金融知道 | 77 万条金融行业问答数据，包括用户提问、网友回答、最佳回答 |
| 法律知道 | 3.6 万条法律问答数据，包括用户提问、网友回答、最佳回答 |
| 联通知道 | 20.3 万条联通问答数据，包括用户提问、网友回答、最佳回答  |
| 农行知道 | 4 万条农业银行问答数据，包括用户提问、网友回答、最佳回答 |
| 保险知道 | 58.8 万条保险行业问答数据，包括用户提问、网友回答、最佳回答 |


## 评测标准
- 查全率：用以评价系统对于潜在答案寻找的全面程度。例如：在回答的前30%中保证一定出现正确答案。
- 查准率：即准确率，top n个答案包含正确答案的概率。这一项与学术界一致。
- 问题解决率：与具体业务和应用场景紧密相关
- 用户满意度/答案满意度：一般对答案满意度的评价方式是在每一次交互后都设置一个评价，客户可以对每一次回答进行评价，评价该答案是否满意。但是这样的评价方式容易让客户厌烦，因为客户是来解决问题的，不是来评价知识库里面的答案是否该优化。
- 问题识别率/应答准确率：指智能客服机器人正确识别出客户的问题数量在所有问题数中的占比。目前业内评价智能机器人比较常用的指标之一。
- 问题预判准确率：指用户进入咨询后，智能客服机器人会对客户可能咨询的问题进行预判。
> 该评测标准是基于京东大数据优势，背靠用户画像体系。通过京东长期数据积累和模型给每个用户添加各种标签，可以提供更个性化和人性化的服务。例如，京东JIMI了解用户的性别、情绪类型、近期购买历史等。当用户开始交流时，就会猜到他可能要询问一个关于母婴商品的使用方法或是一个售后单的退款情况，这就是问题预判。如果预判准确的话，只需在几次甚至一次的交互中获得智能客服机器人专业的问题解答，从而缩短客户咨询时长。
- 意图识别准确率：要想解答用户的问题，机器人首先需要结合上下文环境，从用户提问中准确识别用户咨询的意图是什么，然后返回对应的答案。
- 拦截率：机器人代替人工解决的用户咨询比例
- 24H未转人工率：指客户咨询了智能机器人后的24H内是否有咨询人工客服


## 方法及专利
### FAQ
#### FAQ简介
- Frequently Asked Questions的缩写，意思是“**常见问题解答**”。
#### FAQ方法
1. **QA匹配**：用户输入Query与候选的所有Answer的匹配
2. **QQ匹配**：用户输入Query与历史语料库里找最相似的Query，然后返回找到的Query对应的Answer。即根据用户的新Query去FAQ知识库找到最合适的答案并反馈给用户。

**工业界使用QQ匹配方式比较多**。如蚂蚁金服的智能机器人利用的是QQ匹配的方式。
#### 产品举例
##### 1. YiBot
**1.1 简介**
- YiBot是由深圳追一科技有限公司自主研发，应用目前最前沿的自然语言处理及深度学习算法，为企业级客户提供的一套智能客服机器人系统。

**1.2 FAQ问题优化**
> YiBot的FAQ问题优化是从用户问题和智能客服机器人的回答出发，合理拆分、合并已有FAQ，并优化问句和答案；同时采用问句聚类技术，挖掘新知识点，补充更新已有知识点，淘汰废弃知识点，形成一个正向循环，不断优化知识结构，提高拦截率。
- **FAQ发现**
> 将用户问句进行聚类，对比已有的FAQ，发现并补足未覆盖的知识点。将FAQ与知识点一一对应。
- **FAQ的拆分与合并**
> FAQ拆分是当一个FAQ里包含多个意图或者说多种情况的时候，YiBot后台会自动分析触达率较高的FAQ，聚类FAQ对应的问句，按照意图将其拆分开来。
- **FAQ合并**
> 最终希望希望用户的每一个意图能对应到唯一的FAQ，这样用户每次提问的时候，系统就可以根据这个意图对应的FAQ直接给出答案。而如果两个FAQ意思过于相近，那么当用户问到相关问题时，就不会出现一个直接的回答，而是两个意图相关的推荐问题，这样用户就要再进行一步选择操作。这时候YiBot就会在后台同样是分析触达率较高的FAQ，分析哪一些问句总是被推荐相同的答案，将问句对应的意图合并。
- **淘汰机制**
> 分析历史日志，采用淘汰机制淘汰废弃知识点，如已下线业务知识点等。

**1.3 FAQ答案优化**
- **挖掘对话，进行答案优化**
> 如果机器人已经正确识别意图但最后仍然转人工，说明知识库的答案不对，需要进一步修正这一类知识点相对应的答案。
- **分析头部场景，回答应用文本、图片、自动化解决方案等多元化方式**
> 比如在电商场景中，经常会有查询发货到货时间、订单状态等的场景。利用图示指引、具体订单处理等方式让用户操作更便捷。

##### 2. [百度AnyQ--ANswer Your Questions](https://github.com/baidu/AnyQ)

**2.1 简介**
- AnyQ开源项目主要包含面向FAQ集合的问答系统框架、文本语义匹配工具SimNet。

**2.2 系统框架**
- AnyQ系统框架主要由Question Analysis、Retrieval、Matching、Re-Rank等部分组成。
- 框架中包含的功能均通过插件形式加入，如Analysis中的中文切词，Retrieval中的倒排索引、语义索引，Matching中的Jaccard特征、SimNet语义匹配特征，当前共开放了20+种插件。

**2.3 特色**
- **特色1 框架设计灵活，插件功能丰富，有助于开发者快速构建、快速定制适用于特定业务场景的 FAQ 系统**
> AnyQ 系统集成了检索和匹配的丰富插件，通过配置的方式生效；以相似度计算为例，包括字面匹配相似度 Cosine、Jaccard、BM25 等，同时包含了语义匹配相似度。且所有功能都是通过插件形式加入，用户自定义插件，只需实现对应的接口即可，如 Question 分析方法、检索方式、匹配相似度、排序方式等。
- **特色2 极速语义检索**
> 语义检索技术将用户问题和 FAQ 集合的相似问题通过深度神经网络映射到语义表示空间的临近位置，检索时，通过高速向量索引技术对相似问题进行检索。
- **特色3 业界领先语义匹配技术 SimNet**
> AnyQ 使用 SimNet 语义匹配模型构建文本语义相似度，克服了传统基于字面匹配方法的局限，增强 AnyQ 系统的语义检索和语义匹配能力。
- **其他**：针对无任何训练数据的开发者，AnyQ 还包含了基于百度海量数据训练的语义匹配模型，开发者可零成本直接使用。

##### 3. [腾讯知文--结构化FAQ问答引擎](https://cloud.tencent.com/developer/article/1172017  )
基于结构化的FAQ的问答引擎流程由两条技术路线来解决
- 无监督学习，基于快速检索
- 有监督的学习，基于深度匹配

**3.1 无监督的快速检索方法**
采用了三个层次的方法来实现快速检索的方法
- **层次1：基础的TFIDF提取query的关键词，用BM25来计算query和FAQ库中问题的相似度**。这是典型的词汇统计的方法，该方法可以对rare word比较鲁棒，但同时也存在词汇匹配缺失的问题。
- **层次2：采用了language model（简写LM）的方法**。主要使用的是Jelinek-Mercer平滑法和Dirichlet平滑法，对于上面的词汇匹配问题表现良好，但是也存在平滑敏感的问题。
- **层次3：最后一层使用Embedding，采用了LSA/word2vec和腾讯知文自己提出的Weighted Sum/WMD方法**，以此来表示语义层面的近似，但是也同样引发了歧义问题。

**3.2 监督的深度匹配方法**

采用了两条思路
- **思路1 基于Siamese networks神经网络架构**。这是一种相似性度量方法，内部采用深度语义匹配模型（DSMM，Deep Structured Semantic Model），该方法在检索场景下使用点击数据来训练语义层次的匹配
- **思路2 Interaction-based networks，同时对问题和答案进行特征加权的Attention方案**。

### 自然语言理解(NLU)方法--阿里小蜜
- 无样本冷启动方法：写一套简单易懂的规则表示语法

- 小样本方法：我们先整理出一个大数量级的数据，每一个类目几十条数据，为它建立 meta-learning 任务。对于一个具体任务来说：构建支撑集和预测集，通过 few-shot learning 的方法训练出 model，同时与预测集的 query 进行比较，计算 loss 并更新参数，然后不断迭代让其收敛。这只是一个 meta-learning 任务，我们可以反复抽样获得一系列这样的任务，不断优化同一个模型。在线预测阶段，用户标注的少量样本就是支撑集，将 query 输入模型获得分类结果。模型的神经网络结构分为3部分，首先是 Encoder 将句子变成句子向量，然后再通过 Induction Network 变成类向量，最后通过 Relation Network 计算向量距离，输出最终的结果。具体地，Induction Network中把样本向量抽象到类向量的部分，采用 matrix transformation 的方法，转换后类边界更清晰，更利于下游 relation 的计算。在 Induction Network 的基础上，又可以引入了 memory 机制，形成Memory-based Induction Network ，目的是模仿人类的记忆和类比能力，在效果上又有进一步提升。

- 多样本方法：构建一个三层的模型，最底层是具有较强迁移能力的通用模型 BERT，在此基础上构建不同行业的模型，最后用相对较少的企业数据来训练模型。这样构建出来的企业的 NLU 分类模型，F1 基本都在90%+。性能方面，因为模型的结构比较复杂，在线预测的延时比较长，因此通过知识蒸馏的方法来进行模型压缩，在效果相当的同时预测效率更快了。


### Machine Reading方法--阿里小蜜
#### Machine Reading步骤：
- 文章片段定位：针对用户问题，召回候选文档段落集合，借助文本分类、检索或者问题模板辅助；
- 输入预处理：格式归一，特征预计算问题，及相应段落向量表征，生成文档结构标签；
- 在线预测服务： GPU-Based模型加载及服务驱动，预测段落中词或符号得分；
- 后处理机制：基于动态规划选取最佳文本短语作为输出，拒识：判断是否拒绝回答。

#### 模型结构：
- Embedding Layer：问题及篇章中词向量表示，RNN网络捕捉语序间依赖；
- Attention Layer：对齐问题和篇章，语义相似性计算，引进注意力机制，带着问题找答案；
- Modeling Layer Question-Aware：篇章建模，充分利用问题中信息；
- Output Layer：基于问题和篇章匹配预测答案位置。

### 跨领域迁移学习方法--阿里小蜜
- Fully-Shared Model:用于比较相似的两个领域。
- Specific-Shared Model: 用于相差较大的两个领域。



## 技术难点
1. 数据冷启动的问题

> 解决方案：大致有两种办法：
> - 一是先用一个通用的模型，等到数据足够多的时候优化这个模型；
> - 第二种是先用规则的方法做，先把这个模块做起来，等到数据足够多的时候，再来启用模型的方法，这两种方法都可以走的通，但是要根据具体的情况来具体分析。
2. 用户问题较为口语化，包含大量省略、指代等现象；
3. 用户问题复杂多样，基于字面信息很难精准匹配语义相同问题；
4. 实际产品应用中，对系统鲁棒性、整体性能要求较高
